{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4_PHrOVj51Z"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pytextbook/pytextbook/blob/main/7.2.%20seoul-120-baseline-rnn.ipynb) \n",
    "\n",
    "## RNN (Recurrent Neural Network) 으로 텍스트 분류하기\n",
    "\n",
    "* API Document: https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN\n",
    "\n",
    "## 라이브러리 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CcTgpxw6Aai"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESivktS1lEm7"
   },
   "source": [
    "## 데이터 미리보기 및 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFKC0rSZqNsO"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://bit.ly/seoul-120-text-csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkHHw0dXZ0JE"
   },
   "outputs": [],
   "source": [
    "# 제목과 내용을 합쳐서 문서라는 파생변수 생성\n",
    "df[\"문서\"] = df[\"제목\"] + df[\"내용\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjuWJzWqZ0JF"
   },
   "outputs": [],
   "source": [
    "# value_counts()로 분류별 빈도수 확인\n",
    "df[\"분류\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wnpc5nUZ0JF"
   },
   "outputs": [],
   "source": [
    "# 분류별 빈도수 값으로 불균형이 심해 전체 데이터로 예측을 하면 성능이 떨어질 수 있음\n",
    "# 일부 상위 분류 데이터만을 추출해 사용\n",
    "df = df[df[\"분류\"].isin([\"행정\", \"경제\", \"복지\"])]\n",
    "# df = df[df[\"분류\"].isin([\"행정\", \"경제\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvpvDX5nZ0JG"
   },
   "outputs": [],
   "source": [
    "# 정답(label) 값\n",
    "label_name = \"분류\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VFsfacbZ0JG"
   },
   "outputs": [],
   "source": [
    "# 독립변수(X, 문제)와 종속변수(y, 정답)\n",
    "X = df[\"문서\"]\n",
    "y = df[label_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVldgQfrZ0JH"
   },
   "source": [
    "## label one-hot 형태로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcyzPconsQY5"
   },
   "outputs": [],
   "source": [
    "# get_dummies 를 사용하여 label 값을 one-hot 형태로 생성\n",
    "y_onehot = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaaV4x1AsQY5"
   },
   "outputs": [],
   "source": [
    "# train_test_split 으로 학습과 예측에 사용할 데이터를 나누기\n",
    "# 정답값은 y_onehot 으로 지정\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_onehot, test_size=0.2, random_state=42, stratify=y_onehot)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3b6cgFaJsQY6"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Vm0_ExvnAyN"
   },
   "source": [
    "## Vectorization\n",
    "### Tokenizer\n",
    "\n",
    "1. 이 클래스를 사용하면 각 텍스트를 일련의 정수(각 정수는 사전에 있는 토큰의 인덱스임) 또는 단어 수에 따라 각 토큰의 계수가 이진일 수 있는 벡터로 변환하여 텍스트 말뭉치를 벡터화할 수 있습니다.(tf-idf 기반)\n",
    "\n",
    "2. 매개변수\n",
    "- num_words\n",
    ": 단어 빈도에 따라 유지할 최대 단어 수입니다. 가장 일반적인 단어 만 유지됩니다. \n",
    "-filters\n",
    ": 각 요소가 텍스트에서 필터링될 문자인 문자열입니다. 기본값은 문자를 제외한 모든 구두점과 탭 및 줄 바꿈 '입니다.\n",
    "- lower\n",
    ": 부울. 텍스트를 소문자로 변환할지 여부입니다.\n",
    "- split\n",
    ": str. 단어 분할을 위한 구분 기호입니다.\n",
    "- char_level\n",
    ": True이면 모든 문자가 토큰으로 처리됩니다.\n",
    "- oov_token\n",
    ": 주어진 경우, 그것은 word_index에 추가되고 text_to_sequence 호출 중에 어휘 밖의 단어를 대체하는 데 사용됩니다.\n",
    "\n",
    "3. 벡터화 과정\n",
    "- Tokenizer 인스턴스를 생성\n",
    "- fit_on_texts와 word_index를 사용하여 key value로 이루어진 딕셔너리를 생성\n",
    "- texts_to_sequences를 이용하여 text 문장을 숫자로 이루어진 리스트로 변경\n",
    "- 마지막으로 pad_sequences를 이용하여 리스트의 길이를 통일화\n",
    "\n",
    "\n",
    "* API Document: https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbUdn24iZ0JI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fkbfHCwrYbl"
   },
   "outputs": [],
   "source": [
    "# Tokenizer 는 데이터에 출현하는 모든 단어의 개수를 세고 빈도 수로 정렬해서 \n",
    "# num_words 에 지정된 만큼만 숫자로 반환하고, 나머지는 0 으로 반환\n",
    "# 단어 사전의 크기를 지정해 주기 위해 vocab_size를 지정\n",
    "# vocab_size는 텍스트 데이터의 전체 단어 집합의 크기\n",
    "\n",
    "vocab_size = 1000\n",
    "oov_tok = \"<oov>\"\n",
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token = oov_tok)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qH1gu3mIlFiD"
   },
   "outputs": [],
   "source": [
    "# Tokenizer 에 데이터 실제로 입력합니다.\n",
    "# fit_on_texts와 word_index를 사용하여 key value로 이루어진 딕셔너리를 생성\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71WWs9WVrlXD"
   },
   "outputs": [],
   "source": [
    "# tokenizer의 word_index 속성은 단어와 숫자의 키-값 쌍을 포함하는 딕셔너리를 반환\n",
    "# 이때, 반환 시 자동으로 소문자로 변환되어 들어가며, 느낌표나 마침표 같은 구두점은 자동으로 제거\n",
    "# 각 인덱스에 해당하는 단어가 무엇인지 확인\n",
    "\n",
    "word_to_index = tokenizer.word_index\n",
    "sorted(word_to_index)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TSypRjUdsEB0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 단어별 빈도수를 확인\n",
    "list(tokenizer.word_counts.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-481DN7osWEX"
   },
   "outputs": [],
   "source": [
    "# 단어별 빈도수를 확인\n",
    "word_df = pd.DataFrame(tokenizer.word_counts.items(), columns = ['단어', '빈도수'])\n",
    "word_df.sort_values(by=\"빈도수\", ascending=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drtrcSCkZ0JL"
   },
   "outputs": [],
   "source": [
    "# texts_to_sequences를 이용하여 text 문장을 숫자로 이루어진 리스트로 변경\n",
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MF24eCgKbBS6"
   },
   "source": [
    "## Padding\n",
    "\n",
    "* API Document: https://www.tensorflow.org/tutorials/keras/text_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cemv0J0dbF2h"
   },
   "outputs": [],
   "source": [
    "# 독립변수를 전처리합니다. \n",
    "# 문장의 길이가 제각각인 벡터의 크기를 패딩 작업을 통해 나머지 빈 공간을 0으로 채움\n",
    "# max_length는 패딩의 기준이 됨\n",
    "# padding_type='post' 는 패딩을 앞(기본값)이 아닌 뒤('post')에 채움\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 500\n",
    "padding_type = \"post\"\n",
    "# padding_type = \"pre\"\n",
    "\n",
    "X_train_sp = pad_sequences(train_sequences, padding=padding_type, maxlen=max_length)\n",
    "X_test_sp = pad_sequences(test_sequences, padding=padding_type, maxlen=max_length)\n",
    "\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uInDm3wobb5v"
   },
   "source": [
    "## Modeling\n",
    "\n",
    "### simple RNN\n",
    "\n",
    "* API Document: https://www.tensorflow.org/guide/keras/rnn\n",
    "* API Document: https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yUGUYDs1Z0JM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN, GRU, Bidirectional, LSTM, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbtT1Vdebei7"
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터(모델링할 때 사용자가 직접 세팅해주는 값)을 설정\n",
    "# vocab_size는 텍스트 데이터의 전체 단어 집합의 크기\n",
    "# embedding_dim는 임베딩 할 벡터의 차원\n",
    "# max_length는 패딩의 기준\n",
    "\n",
    "embedding_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATWh1mLDZ0JN"
   },
   "outputs": [],
   "source": [
    "# 클래스의 수는 분류될 예측값의 종류\n",
    "# 정답값이 one-hot 형태로 인코딩 되어 있기 때문에 정답값의 컬럼의 수가 예측값의 종류가 됨\n",
    "n_class = y_train.shape[1]\n",
    "n_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VyRptbe9bjP-"
   },
   "outputs": [],
   "source": [
    "# # Simple RNN 레이어를 사용한 모델 (model_rnn) 정의\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "# model.add(SimpleRNN(units=64, return_sequences=True))\n",
    "# model.add(SimpleRNN(units=32))\n",
    "# model.add(Dense(units=10))\n",
    "# model.add(Dropout(0.1))\n",
    "# model.add(Dense(n_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9RwuUKIsQY-"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "#     BatchNormalization(),\n",
    "    Bidirectional(LSTM(32)),\n",
    "#     Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(n_class, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBglNGeFZ0JN"
   },
   "source": [
    "* https://www.tensorflow.org/guide/keras/rnn#%EC%96%91%EB%B0%A9%ED%96%A5_rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bbId7zpZ0JN"
   },
   "source": [
    "### Bidirectional LSTM\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1600px-Long_Short-Term_Memory.svg.png\" width=\"400\">\n",
    "\n",
    "* 출처 : https://ko.wikipedia.org/wiki/%EC%88%9C%ED%99%98_%EC%8B%A0%EA%B2%BD%EB%A7%9D\n",
    "\n",
    "* API Document: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJi6uCatI54I"
   },
   "source": [
    "### GRU\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Gated_Recurrent_Unit%2C_base_type.svg/440px-Gated_Recurrent_Unit%2C_base_type.svg.png\" width=\"400\">\n",
    "\n",
    "* API Document: https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63MyG_CEZ0JN"
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "# model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "# model.add(Bidirectional(LSTM(32)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(n_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TD6brH6LZ0JN"
   },
   "source": [
    "## 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_uYPV_gbZ0JO"
   },
   "outputs": [],
   "source": [
    "# 여러개 정답 중 하나 맞추는 문제이며, 정답값이 one-hot 형태이기 때문에\n",
    "# 손실 함수는 categorical_crossentropy를 사용\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= 'adam',\n",
    "              metrics = ['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6Z8ZNu-Z0JO"
   },
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrK3Wa0VsQZA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cj9vQS6msQZA"
   },
   "outputs": [],
   "source": [
    "# 모델 학습을 실행\n",
    "history = model.fit(X_train_sp, y_train, \n",
    "                    epochs=100, batch_size=64, callbacks=early_stop, validation_split=0.2,\n",
    "                    use_multiprocessing=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMnumSxuZ0JO"
   },
   "outputs": [],
   "source": [
    "# 모델 학습의 결과값을 데이터 프레임으로 만들어 확인\n",
    "df_hist = pd.DataFrame(history.history)\n",
    "df_hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCU7v3_Ec5eA"
   },
   "outputs": [],
   "source": [
    "# 모델 학습 결과을 그래프로 시각화\n",
    "df_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixIPPgKgZ0JP"
   },
   "outputs": [],
   "source": [
    "df_hist[[\"accuracy\", \"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uB6Dx0Xzty4U"
   },
   "outputs": [],
   "source": [
    "df_hist[[\"loss\", \"val_loss\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFpNLGzUZ0JP"
   },
   "source": [
    "## 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-jaBsHTt7Ri"
   },
   "outputs": [],
   "source": [
    "# predict() 메서드로 모델 예측\n",
    "y_pred = model.predict(X_test_sp)\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTE70dO3Z0JP"
   },
   "source": [
    "## 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUvRhKTVuXFR"
   },
   "outputs": [],
   "source": [
    "# numpy.argmax를 이용해 가장 큰 값의 인덱스들을 반환한 값(클래스 예측)을 y_predict에 할당\n",
    "y_predict = np.argmax(y_pred, axis=1)\n",
    "y_predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WaTm4zwMZ0JP"
   },
   "outputs": [],
   "source": [
    "# numpy.argmax를 이용해 가장 큰 값의 인덱스들을 반환한 값(클래스 예측)을 y_test_val에 할당\n",
    "y_test_val = np.argmax(y_test.values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXe_vRQmZ0JP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 실제값과 예측값을 비교하여 맞춘 값의 평균을 확인\n",
    "(y_test_val == y_predict).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LftFDAHXIIXM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델에 설정된 손실 값 및 메트릭 값을 반환하여 평가\n",
    "test_loss, test_acc = model.evaluate(X_test_sp, y_test)\n",
    "test_loss, test_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0EVMWhcsQZB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
